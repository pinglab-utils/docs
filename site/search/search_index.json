{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ICD 11 Code Tools This online documents has been prepared for ICD 11 Code Tools development and implementation. The document begins with the setting up of tools and environment required for platform creation. A systematic steps for Indexing, Graph database and NoSQL database integration and development is presented. Implementation of AI search algorithms and development of models are introduced. Figure : Counting number of decendent nodes in each categories of ICD 11 code trees.","title":"Home"},{"location":"#icd-11-code-tools","text":"This online documents has been prepared for ICD 11 Code Tools development and implementation. The document begins with the setting up of tools and environment required for platform creation. A systematic steps for Indexing, Graph database and NoSQL database integration and development is presented. Implementation of AI search algorithms and development of models are introduced. Figure : Counting number of decendent nodes in each categories of ICD 11 code trees.","title":"ICD 11 Code Tools"},{"location":"comingsoon/","text":"Coming Soon Under construction","title":"Comingsoon"},{"location":"comingsoon/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"workflow/","text":"Cloud Articture and Workflow This online documents has been prepared for ICD 11 Code Tools development and implementation. The document begins with the setting up of tools and environment required for platform creation. A systematic steps for Indexing, Graph database and NoSQL database integration and development is presented. Implementation of AI search algorithms and development of models are introduced. Figure : Platform architecture and workflow","title":"Workflow"},{"location":"workflow/#cloud-articture-and-workflow","text":"This online documents has been prepared for ICD 11 Code Tools development and implementation. The document begins with the setting up of tools and environment required for platform creation. A systematic steps for Indexing, Graph database and NoSQL database integration and development is presented. Implementation of AI search algorithms and development of models are introduced. Figure : Platform architecture and workflow","title":"Cloud Articture and Workflow"},{"location":"GettingStarted/anaconda/","text":"Installing Python To install Anaconda Python follow the instruction at Anaconda Distribution Website . Based on the operating system select the proper version of the Anaconda package and install it in your PC. After you successfully install the proper version, you will get anaconda application in you PC which will look like the figure below: Best way to start with is the \"Jupyter notebook\". Lunch the jupyter notebook to start with Python. Note- Linux: For Linux user, it could be little bit tricky. SOme time it becomes hard to locate anaconda path to the environment so you need to point the python you want to use. Please, run the command below to point the python: bash export PATH=/home/ubuntu/anaconda3/bin:$PATH There is 'base' or 'anaconda3' environment by defult. You can find the list of available environmet by typing following command on the terminal bash conda env list To start the 'base' environment type bash source activate base To install new package for example 'jupyter notebook' type bash pip install jupyter notebook After sucessfully installing Jupyter notebook, tye following to start it bash Jupyter notebook Note - Cloud For running Jupyter notebook in AWS cloud, it is important to open the \"8888\" to \"8889\" with TCP rule with IP \"0.0.0.0\" and allow to be opend from anywhere. Once port is open, type following to bash jupyter notebook --ip=0.0.0.0 --no-browser","title":"Setting up Python"},{"location":"GettingStarted/anaconda/#installing-python","text":"To install Anaconda Python follow the instruction at Anaconda Distribution Website . Based on the operating system select the proper version of the Anaconda package and install it in your PC. After you successfully install the proper version, you will get anaconda application in you PC which will look like the figure below: Best way to start with is the \"Jupyter notebook\". Lunch the jupyter notebook to start with Python.","title":"Installing Python"},{"location":"GettingStarted/anaconda/#note-linux","text":"For Linux user, it could be little bit tricky. SOme time it becomes hard to locate anaconda path to the environment so you need to point the python you want to use. Please, run the command below to point the python: bash export PATH=/home/ubuntu/anaconda3/bin:$PATH There is 'base' or 'anaconda3' environment by defult. You can find the list of available environmet by typing following command on the terminal bash conda env list To start the 'base' environment type bash source activate base To install new package for example 'jupyter notebook' type bash pip install jupyter notebook After sucessfully installing Jupyter notebook, tye following to start it bash Jupyter notebook","title":"Note- Linux:"},{"location":"GettingStarted/anaconda/#note-cloud","text":"For running Jupyter notebook in AWS cloud, it is important to open the \"8888\" to \"8889\" with TCP rule with IP \"0.0.0.0\" and allow to be opend from anywhere. Once port is open, type following to bash jupyter notebook --ip=0.0.0.0 --no-browser","title":"Note - Cloud"},{"location":"GettingStarted/env/","text":"Python Environment Basics To avoid errors later, it's best to update all the packages in the default environment. Open the Anaconda Prompt application. In the prompt, run the following commands: conda upgrade conda conda upgrade --all If you are seeing the following \"conda command not found\" and are using ZShell, you have to do the following: export PATH = \"/Users/username/anaconda/bin: $PATH \" or update above command line to your .zsh_config file. Once you have Anaconda installed, managing packages is fairly straightforward. To install a package, type conda install package_name in your terminal. For example, to install numpy, type conda install numpy. You can install multiple packages at the same time. Something like conda install numpy scipy pandas will install all those packages simultaneously. It's also possible to specify which version of a package you want by adding the version number such as conda install numpy = 1 .10. Conda also automatically installs dependencies for you. For example scipy depends on numpy, it uses and requires numpy. If you install just scipy (conda install scipy), Conda will also install numpy if it isn't already installed. Most of the commands are pretty intuitive. To uninstall, use conda remove package_name To update a package conda update package_name If you want to update all packages in an environment, which is often useful, use conda update --all And finally, to list installed packages, it's conda list If you don't know the exact name of the package you're looking for, you can try searching with conda search search_term For example, I know I want to install Beautiful Soup, but I'm not sure of the exact package name. So, I try conda search beautifulsoup Environments Conda can be used to create environments to isolate your projects. To create an environment, use conda create -n env_name list of packages in your terminal Here -n env_name sets the name of your environment (-n for name) and list of packages is the list of packages you want installed in the environment. For example, to create an environment named my_env and install numpy in it, type conda create -n my_env numpy When creating an environment, you can specify which version of Python to install in the environment. This is useful when you're working with code in both Python 2.x and Python 3.x. To create an environment with a specific Python version, do something like conda create -n py3 python = 3 or conda create -n py2 python = 2 I actually have both of these environments on my personal computer. I use them as general environments not tied to any specific project, but rather for general work with each Python version easily accessible. These commands will install the most recent version of Python 3 and 2, respectively. To install a specific version, use conda create -n py python = 3 .3 for Python 3.3. Once you have an environment created, use source activate my_env to enter it on OSX/Linux. On Windows, use activate my_env When you're in the environment, you'll see the environment name in the terminal prompt. Something like (my_env) ~ $. The environment has only a few packages installed by default, plus the ones you installed when creating it. You can check this out with conda list. Installing packages in the environment is the same as before: conda install package_name Only this time, the specific packages you install will only be available when you're in the environment. To leave the environment, type source deactivate ( on OSX/Linux ) On Windows, use deactivate Saving and loading environments A really useful feature is sharing environments so others can install all the packages used in your code, with the correct versions. You can save the packages to a YAML file with conda env export > environment.yaml The first part conda env export writes out all the packages in the environment, including the Python version. Above you can see the name of the environment and all the dependencies (along with versions) are listed. The second part of the export command, > environment.yaml writes the exported text to a YAML file environment.yaml . This file can now be shared and others will be able to create the same environment you used for the project. To create an environment from an environment file use conda env create -f environment.yaml This will create a new environment with the same name listed in environment.yaml . Listing environments If you forget what your environments are named (happens to me sometimes), use conda env list to list out all the environments you've created. You should see a list of environments, there will be an asterisk next to the environment you're currently in. The default environment, the environment used when you aren't in one, is called root . Removing environments If there are environments you don't use anymore, conda env remove -n env_name will remove the specified environment (here, named env_name ). Using environments One thing that\u2019s helped me tremendously is having separate environments for Python 2 and Python 3. I used conda create -n py2 python = 2 and conda create -n py3 python = 3 to create two separate environments, py2 and py3 . Now I have a general use environment for each Python version. In each of those environments, I've installed most of the standard data science packages (numpy, scipy, pandas, etc.) I\u2019ve also found it useful to create environments for each project I\u2019m working on. It works great for non-data related projects too like web apps with Flask. For example, I have an environment for my personal blog using Pelican . Sharing environments When sharing your code on GitHub, it's good practice to make an environment file and include it in the repository. This will make it easier for people to install all the dependencies for your code. I also usually include a pip requirements.txt file using pip freeze ( learn more here ) for people not using conda. More to learn To learn more about conda and how it fits in the Python ecosystem, check out this article by Jake Vanderplas: Conda myths and misconceptions. And here's the conda documentation you can reference later.","title":"Setting up Node"},{"location":"GettingStarted/env/#python-environment","text":"","title":"Python Environment"},{"location":"GettingStarted/env/#basics","text":"To avoid errors later, it's best to update all the packages in the default environment. Open the Anaconda Prompt application. In the prompt, run the following commands: conda upgrade conda conda upgrade --all If you are seeing the following \"conda command not found\" and are using ZShell, you have to do the following: export PATH = \"/Users/username/anaconda/bin: $PATH \" or update above command line to your .zsh_config file. Once you have Anaconda installed, managing packages is fairly straightforward. To install a package, type conda install package_name in your terminal. For example, to install numpy, type conda install numpy. You can install multiple packages at the same time. Something like conda install numpy scipy pandas will install all those packages simultaneously. It's also possible to specify which version of a package you want by adding the version number such as conda install numpy = 1 .10. Conda also automatically installs dependencies for you. For example scipy depends on numpy, it uses and requires numpy. If you install just scipy (conda install scipy), Conda will also install numpy if it isn't already installed. Most of the commands are pretty intuitive. To uninstall, use conda remove package_name To update a package conda update package_name If you want to update all packages in an environment, which is often useful, use conda update --all And finally, to list installed packages, it's conda list If you don't know the exact name of the package you're looking for, you can try searching with conda search search_term For example, I know I want to install Beautiful Soup, but I'm not sure of the exact package name. So, I try conda search beautifulsoup","title":"Basics"},{"location":"GettingStarted/env/#environments","text":"Conda can be used to create environments to isolate your projects. To create an environment, use conda create -n env_name list of packages in your terminal Here -n env_name sets the name of your environment (-n for name) and list of packages is the list of packages you want installed in the environment. For example, to create an environment named my_env and install numpy in it, type conda create -n my_env numpy When creating an environment, you can specify which version of Python to install in the environment. This is useful when you're working with code in both Python 2.x and Python 3.x. To create an environment with a specific Python version, do something like conda create -n py3 python = 3 or conda create -n py2 python = 2 I actually have both of these environments on my personal computer. I use them as general environments not tied to any specific project, but rather for general work with each Python version easily accessible. These commands will install the most recent version of Python 3 and 2, respectively. To install a specific version, use conda create -n py python = 3 .3 for Python 3.3. Once you have an environment created, use source activate my_env to enter it on OSX/Linux. On Windows, use activate my_env When you're in the environment, you'll see the environment name in the terminal prompt. Something like (my_env) ~ $. The environment has only a few packages installed by default, plus the ones you installed when creating it. You can check this out with conda list. Installing packages in the environment is the same as before: conda install package_name Only this time, the specific packages you install will only be available when you're in the environment. To leave the environment, type source deactivate ( on OSX/Linux ) On Windows, use deactivate","title":"Environments"},{"location":"GettingStarted/env/#saving-and-loading-environments","text":"A really useful feature is sharing environments so others can install all the packages used in your code, with the correct versions. You can save the packages to a YAML file with conda env export > environment.yaml The first part conda env export writes out all the packages in the environment, including the Python version. Above you can see the name of the environment and all the dependencies (along with versions) are listed. The second part of the export command, > environment.yaml writes the exported text to a YAML file environment.yaml . This file can now be shared and others will be able to create the same environment you used for the project. To create an environment from an environment file use conda env create -f environment.yaml This will create a new environment with the same name listed in environment.yaml .","title":"Saving and loading environments"},{"location":"GettingStarted/env/#listing-environments","text":"If you forget what your environments are named (happens to me sometimes), use conda env list to list out all the environments you've created. You should see a list of environments, there will be an asterisk next to the environment you're currently in. The default environment, the environment used when you aren't in one, is called root .","title":"Listing environments"},{"location":"GettingStarted/env/#removing-environments","text":"If there are environments you don't use anymore, conda env remove -n env_name will remove the specified environment (here, named env_name ).","title":"Removing environments"},{"location":"GettingStarted/env/#using-environments","text":"One thing that\u2019s helped me tremendously is having separate environments for Python 2 and Python 3. I used conda create -n py2 python = 2 and conda create -n py3 python = 3 to create two separate environments, py2 and py3 . Now I have a general use environment for each Python version. In each of those environments, I've installed most of the standard data science packages (numpy, scipy, pandas, etc.) I\u2019ve also found it useful to create environments for each project I\u2019m working on. It works great for non-data related projects too like web apps with Flask. For example, I have an environment for my personal blog using Pelican .","title":"Using environments"},{"location":"GettingStarted/env/#sharing-environments","text":"When sharing your code on GitHub, it's good practice to make an environment file and include it in the repository. This will make it easier for people to install all the dependencies for your code. I also usually include a pip requirements.txt file using pip freeze ( learn more here ) for people not using conda.","title":"Sharing environments"},{"location":"GettingStarted/env/#more-to-learn","text":"To learn more about conda and how it fits in the Python ecosystem, check out this article by Jake Vanderplas: Conda myths and misconceptions. And here's the conda documentation you can reference later.","title":"More to learn"},{"location":"GettingStarted/git/","text":"How to git Reference : How to Git Create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files. You can add these files after your project has been pushed to GitHub. Open Terminal. Change the current working directory to your local project. Initialize the local directory as a Git repository. git init Add the files in your new local repository. This stages them for the first commit. git add . Adds the files in the local repository and stages them for commit. To unstage a file, use 'git reset HEAD YOUR-FILE'. Commit the files that you've staged in your local repository. git commit -m \"First commit\" Commits the tracked changes and prepares them to be pushed to a remote repository. To remove this commit and modify the file, use 'git reset --soft HEAD~1' and commit and add the file again. Copy remote repository URL fieldAt the top of your GitHub repository's Quick Setup page, click to copy the remote repository URL. In Terminal, add the URL for the remote repository where your local repository will be pushed. git remote add origin remote repository URL Sets the new remote git remote -v Verifies the new remote URL Push the changes in your local repository to GitHub. git push origin master Pushes the changes in your local repository up to the remote repository you specified as the origin","title":"Setting up Git"},{"location":"GettingStarted/git/#how-to-git","text":"Reference : How to Git Create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files. You can add these files after your project has been pushed to GitHub. Open Terminal. Change the current working directory to your local project. Initialize the local directory as a Git repository. git init Add the files in your new local repository. This stages them for the first commit. git add . Adds the files in the local repository and stages them for commit. To unstage a file, use 'git reset HEAD YOUR-FILE'. Commit the files that you've staged in your local repository. git commit -m \"First commit\" Commits the tracked changes and prepares them to be pushed to a remote repository. To remove this commit and modify the file, use 'git reset --soft HEAD~1' and commit and add the file again. Copy remote repository URL fieldAt the top of your GitHub repository's Quick Setup page, click to copy the remote repository URL. In Terminal, add the URL for the remote repository where your local repository will be pushed. git remote add origin remote repository URL Sets the new remote git remote -v Verifies the new remote URL Push the changes in your local repository to GitHub. git push origin master Pushes the changes in your local repository up to the remote repository you specified as the origin","title":"How to git"},{"location":"GettingStarted/jupyter/","text":"Installing Jupyter Notebook By far the easiest way to install Jupyter is with Anaconda. Jupyter notebooks automatically come with the distribution. You'll be able to use notebooks from the default environment. To install Jupyter notebooks in a conda environment, use conda install jupyter notebook Jupyter notebooks are also available through pip with pip install jupyter notebook Markdown Cheatsheet : https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet Convert a notebook to an HTML file, in your terminal use jupyter nbconvert --to html notebook.ipynb Convert: https://nbconvert.readthedocs.io/en/latest/usage.html To create the slideshow from the notebook file, you'll need to use nbconvert: jupyter nbconvert notebook.ipynb --to slides This just converts the notebook to the necessary files for the slideshow, but you need to serve it with an HTTP server to actually see the presentation. To convert it and immediately see it, use jupyter nbconvert notebook.ipynb --to slides --post serve This will open up the slideshow in your browser so you can present it. panda presentation: presentation","title":"Setting up Elasticsearch"},{"location":"GettingStarted/jupyter/#installing-jupyter-notebook","text":"By far the easiest way to install Jupyter is with Anaconda. Jupyter notebooks automatically come with the distribution. You'll be able to use notebooks from the default environment. To install Jupyter notebooks in a conda environment, use conda install jupyter notebook Jupyter notebooks are also available through pip with pip install jupyter notebook Markdown Cheatsheet : https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet Convert a notebook to an HTML file, in your terminal use jupyter nbconvert --to html notebook.ipynb Convert: https://nbconvert.readthedocs.io/en/latest/usage.html To create the slideshow from the notebook file, you'll need to use nbconvert: jupyter nbconvert notebook.ipynb --to slides This just converts the notebook to the necessary files for the slideshow, but you need to serve it with an HTTP server to actually see the presentation. To convert it and immediately see it, use jupyter nbconvert notebook.ipynb --to slides --post serve This will open up the slideshow in your browser so you can present it. panda presentation: presentation","title":"Installing Jupyter Notebook"},{"location":"GettingStarted/lib/","text":"Python Libraries Following are the best Python Libraries: TensorFlow Scikit-Learn Numpy Keras PyTorch LightGBM Eli5 SciPy Theano Pandas","title":"Setting up Neo4J"},{"location":"GettingStarted/lib/#python-libraries","text":"Following are the best Python Libraries: TensorFlow Scikit-Learn Numpy Keras PyTorch LightGBM Eli5 SciPy Theano Pandas","title":"Python Libraries"},{"location":"algorithms/alg-I/","text":"","title":"Algorithms - I"},{"location":"algorithms/alg-II/","text":"","title":"Algorithms - II"},{"location":"algorithms/alg-III/","text":"","title":"Algorithms - II"},{"location":"download/download/","text":"ICD 11 Download Pipeline Setting up API To download ICD11 data you need to use the API provided at: https://icd.who.int/icdapi . In order to gain access to the API you need to create an account and use the client key provided. With the client key you are now able to access all of the endpoints specified in the API documentation . The rest of this guide uses the ICD11 module from the ping lab utils package. You can find and clone the module here: https://github.com/salviStudent/testing/tree/master/testing-master . Working Directory and Additonal Dependencies For the simplest use you need to have a json file named config.json in your working directory. The config file needs to have the following: { \"ClientId\":\"your_client_id\", \"ClientSecret\": \"your_client_secret\" } where your_client_id and your_client_secret are your client and secret keys respectively. Along with this config file ICD11.py only needs the request module to function. You can install it by running pip3 install requests if it is not already installed. Getting started Once all of this is in place you are ready to start downloading ICD-11 data. As an example we show the results from the ICD-11 code corresponding to hypertensive heart disease. from ICD11 import icd11_data hypertensive_heart_disease = icd11_data( \"1210166201\" ) print (hypetensive_heart_disease) This outputs: { '@context' : 'http://id.who.int/icd/contexts/contextForFoundationEntity.json' , '@id' : 'http://id.who.int/icd/entity/1210166201' , 'parent' : [ 'http://id.who.int/icd/entity/924915526' , 'http://id.who.int/icd/entity/1395497138' ], 'child' : [ 'http://id.who.int/icd/entity/600660459' , 'http://id.who.int/icd/entity/1208029865' ], 'browserUrl' : 'NA' , 'title' : { '@language' : 'en' , '@value' : 'Hypertensive heart disease' }, 'synonym' : [ { 'label' : { '@language' : 'en' , '@value' : 'HHD - [hypertensive heart disease]' } }, { 'label' : { '@language' : 'en' , '@value' : 'hypertensive cardiac disease' } } ], 'definition' : { '@language' : 'en' , '@value' : 'Uncontrolled and prolonged hypertension can lead to a variety of changes in the myocardial structure, coronary vasculature, and conduction system of the heart. Hypertensive heart disease is a term applied generally to heart diseases, such as left ventricular hypertrophy, coronary artery disease, cardiac arrhythmias, and congestive heart failure, that are caused by direct or indirect effects hypertension.' } }","title":"Download Pipeline"},{"location":"download/download/#icd-11-download-pipeline","text":"","title":"ICD 11 Download Pipeline"},{"location":"download/download/#setting-up-api","text":"To download ICD11 data you need to use the API provided at: https://icd.who.int/icdapi . In order to gain access to the API you need to create an account and use the client key provided. With the client key you are now able to access all of the endpoints specified in the API documentation . The rest of this guide uses the ICD11 module from the ping lab utils package. You can find and clone the module here: https://github.com/salviStudent/testing/tree/master/testing-master .","title":"Setting up API"},{"location":"download/download/#working-directory-and-additonal-dependencies","text":"For the simplest use you need to have a json file named config.json in your working directory. The config file needs to have the following: { \"ClientId\":\"your_client_id\", \"ClientSecret\": \"your_client_secret\" } where your_client_id and your_client_secret are your client and secret keys respectively. Along with this config file ICD11.py only needs the request module to function. You can install it by running pip3 install requests if it is not already installed.","title":"Working Directory and Additonal Dependencies"},{"location":"download/download/#getting-started","text":"Once all of this is in place you are ready to start downloading ICD-11 data. As an example we show the results from the ICD-11 code corresponding to hypertensive heart disease. from ICD11 import icd11_data hypertensive_heart_disease = icd11_data( \"1210166201\" ) print (hypetensive_heart_disease) This outputs: { '@context' : 'http://id.who.int/icd/contexts/contextForFoundationEntity.json' , '@id' : 'http://id.who.int/icd/entity/1210166201' , 'parent' : [ 'http://id.who.int/icd/entity/924915526' , 'http://id.who.int/icd/entity/1395497138' ], 'child' : [ 'http://id.who.int/icd/entity/600660459' , 'http://id.who.int/icd/entity/1208029865' ], 'browserUrl' : 'NA' , 'title' : { '@language' : 'en' , '@value' : 'Hypertensive heart disease' }, 'synonym' : [ { 'label' : { '@language' : 'en' , '@value' : 'HHD - [hypertensive heart disease]' } }, { 'label' : { '@language' : 'en' , '@value' : 'hypertensive cardiac disease' } } ], 'definition' : { '@language' : 'en' , '@value' : 'Uncontrolled and prolonged hypertension can lead to a variety of changes in the myocardial structure, coronary vasculature, and conduction system of the heart. Hypertensive heart disease is a term applied generally to heart diseases, such as left ventricular hypertrophy, coronary artery disease, cardiac arrhythmias, and congestive heart failure, that are caused by direct or indirect effects hypertension.' } }","title":"Getting started"},{"location":"explore/explore/","text":"","title":"Exploratory Data Analysis"},{"location":"flask/flask/","text":"","title":"Flask Implementation"},{"location":"graph/graph/","text":"","title":"Graphical Database"},{"location":"indexing/indexing/","text":"","title":"Indexing"},{"location":"intro/","text":"Quanta.Guru This online document helps the absolute beginners to persue the future direction in coding and Quantum Computing. The lesson starts with fundamental of qubits, quantum gates and quantum circuits, quantum algorithms and quantum machine learning. Learning Track: QUANTUM GATES Getting Started Single Qubit Gates Multiple Qubits Gates QUANTUM CIRCUITS Hadamard Gate Bell State Random Variables ALGORITHMS Quantum Fourier Transform Linear Equation (HHL) Shor's Algorithm Grover's Algorithm OPTIMIZATION Binary Quadratic Model (BQM) Vahicle Routing Travelling Salsesman QUANTUM MACHINE LEARNING Quantum SVM","title":"Quanta.Guru"},{"location":"intro/#quantaguru","text":"This online document helps the absolute beginners to persue the future direction in coding and Quantum Computing. The lesson starts with fundamental of qubits, quantum gates and quantum circuits, quantum algorithms and quantum machine learning.","title":"Quanta.Guru"},{"location":"intro/#learning-track","text":"","title":"Learning Track:"},{"location":"intro/#quantum-gates","text":"Getting Started Single Qubit Gates Multiple Qubits Gates","title":"QUANTUM GATES"},{"location":"intro/#quantum-circuits","text":"Hadamard Gate Bell State Random Variables","title":"QUANTUM CIRCUITS"},{"location":"intro/#algorithms","text":"Quantum Fourier Transform Linear Equation (HHL) Shor's Algorithm Grover's Algorithm","title":"ALGORITHMS"},{"location":"intro/#optimization","text":"Binary Quadratic Model (BQM) Vahicle Routing Travelling Salsesman","title":"OPTIMIZATION"},{"location":"intro/#quantum-machine-learning","text":"Quantum SVM","title":"QUANTUM MACHINE LEARNING"},{"location":"intro/comingsoon/","text":"Coming Soon Under construction","title":"Comingsoon"},{"location":"intro/comingsoon/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"intro/qiskit/","text":"Getting Started with Qiskit Here, we provide an overview of working with Qiskit. Qiskit provides the basic building blocks necessary to program quantum computers. The fundamental unit of Qiskit is the quantum circuit . A workflow using Qiskit consists of two stages: Build and Execute . Build allows you to make different quantum circuits that represent the problem you are solving, and Execute allows you to run them on different backends. After the jobs have been run, the data is collected. There are methods for putting this data together, depending on the program. This either gives you the answer you wanted, or allows you to make a better program for the next instance. import numpy as np from qiskit import * % matplotlib inline Circuit Basics Building the circuit The basic elements needed for your first program are the QuantumCircuit, and QuantumRegister. # Create a Quantum Register with 3 qubits. q = QuantumRegister( 3 , 'q' ) # Create a Quantum Circuit acting on the q register circ = QuantumCircuit(q) Note: Naming the QuantumRegister is optional and not required. After you create the circuit with its registers, you can add gates (\"operations\") to manipulate the registers. As you proceed through the tutorials you will find more gates and circuits; below is an example of a quantum circuit that makes a three-qubit GHZ state $$|\\psi\\rangle = \\left(|000\\rangle+|111\\rangle\\right)/\\sqrt{2}.$$ To create such a state, we start with a three-qubit quantum register. By default, each qubit in the register is initialized to\\(|0\\rangle\\)To make the GHZ state, we apply the following gates: * A Hadamard gate\\(H\\)on qubit 0, which puts it into a superposition state. * A controlled-Not operation ($C_{X}$) between qubit 0 and qubit 1. * A controlled-Not operation between qubit 0 and qubit 2. On an ideal quantum computer, the state produced by running this circuit would be the GHZ state above. In Qiskit, operations can be added to the circuit one by one, as shown below. # Add a H gate on qubit 0, putting this qubit in superposition. circ . h(q[ 0 ]) # Add a CX (CNOT) gate on control qubit 0 and target qubit 1, putting # the qubits in a Bell state. circ . cx(q[ 0 ], q[ 1 ]) # Add a CX (CNOT) gate on control qubit 0 and target qubit 2, putting # the qubits in a GHZ state. circ . cx(q[ 0 ], q[ 2 ]) <qiskit.extensions.standard.cx.CnotGate at 0x122bbc1d0> Visualize Circuit You can visualize your circuit using Qiskit QuantumCircuit.draw() , which plots the circuit in the form found in many textbooks. circ . draw() In this circuit, the qubits are put in order, with qubit zero at the top and qubit two at the bottom. The circuit is read left to right (meaning that gates that are applied earlier in the circuit show up further to the left). Simulating circuits using Qiskit Aer Qiskit Aer is our package for simulating quantum circuits. It provides many different backends for doing a simulation. Here we use the basic Python version. Statevector backend The most common backend in Qiskit Aer is the statevector_simulator . This simulator returns the quantum state, which is a complex vector of dimensions\\(2^n\\), where \\(n\\) is the number of qubits (so be careful using this as it will quickly get too large to run on your machine). When representing the state of a multi-qubit system, the tensor order used in Qiskit is different than that used in most physics textbooks. Suppose there are \\( n \\) qubits, and qubit \\(j\\) is labeled as \\(Q_{j}\\) Qiskit uses an ordering in which the \\(n^{\\mathrm{th}} \\) qubit is on the left side of the tensor product, so that the basis vectors are labeled as \\(Q_n\\otimes \\cdots \\otimes Q_1\\otimes Q_0\\). For example, if qubit zero is in state 0, qubit 1 is in state 0, and qubit 2 is in state 1, Qiskit would represent this state as\\(|100\\rangle\\), whereas many physics textbooks would represent it as\\(|001\\rangle\\). This difference in labeling affects the way multi-qubit operations are represented as matrices. For example, Qiskit represents a controlled-X (\\( C_{X}\\) operation with qubit 0 being the control and qubit 1 being the target as $$C_X = \\begin{pmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ \\end{pmatrix}.$$ To run the above circuit using the statevector simulator, first you need to import Aer and then set the backend to statevector_simulator . # Import Aer from qiskit import BasicAer # Run the quantum circuit on a statevector simulator backend backend = BasicAer . get_backend( 'statevector_simulator' ) Now that we have chosen the backend, it's time to compile and run the quantum circuit. In Qiskit we provide the execute function for this. execute returns a job object that encapsulates information about the job submitted to the backend. Tip: You can obtain the above parameters in Jupyter. Simply place the text cursor on a function and press Shift+Tab. # Create a Quantum Program for execution job = execute(circ, backend) When you run a program, a job object is made that has the following two useful methods: job.status() and job.result() , which return the status of the job and a result object, respectively. Note: Jobs run asynchronously, but when the result method is called, it switches to synchronous and waits for it to finish before moving on to another task. result = job . result() The results object contains the data and Qiskit provides the method result.get_statevector(circ) to return the state vector for the quantum circuit. outputstate = result . get_statevector(circ, decimals = 3 ) print (outputstate) [0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j] Qiskit also provides a visualization toolbox to allow you to view these results. Below, we use the visualization function to plot the real and imaginary components of the state density matrix \\rho. from qiskit.visualization import plot_state_city plot_state_city(outputstate) Unitary backend Qiskit Aer also includes a unitary_simulator that works provided all the elements in the circuit are unitary operations . This backend calculates the \\(2^n \\times 2^n\\) matrix representing the gates in the quantum circuit. # Run the quantum circuit on a unitary simulator backend backend = BasicAer . get_backend( 'unitary_simulator' ) job = execute(circ, backend) result = job . result() # Show the results print (result . get_unitary(circ, decimals = 3 )) [[ 0.707+0.j 0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j -0.707+0.j] [ 0. +0.j 0. +0.j 0.707+0.j 0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j -0.707+0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j 0.707+0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0.707+0.j -0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j 0.707+0.j] [ 0.707+0.j -0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j]] OpenQASM backend The simulators above are useful because they provide information about the state output by the ideal circuit and the matrix representation of the circuit. However, a real experiment terminates by measuring each qubit (usually in the computational\\(|0\\rangle, |1\\rangle\\)basis). Without measurement, we cannot gain information about the state. Measurements cause the quantum system to collapse into classical bits. For example, suppose we make independent measurements on each qubit of the three-qubit GHZ state $$|\\psi\\rangle = |000\\rangle +|111\\rangle)/\\sqrt{2},$$ and let\\(xyz\\)denote the bitstring that results. Recall that, under the qubit labeling used by Qiskit,\\(x\\)would correspond to the outcome on qubit 2,\\(y\\)to the outcome on qubit 1, and\\(z\\)to the outcome on qubit 0. Note: This representation of the bitstring puts the most significant bit (MSB) on the left, and the least significant bit (LSB) on the right. This is the standard ordering of binary bitstrings. We order the qubits in the same way, which is why Qiskit uses a non-standard tensor product order. Recall the probability of obtaining outcome\\(xyz\\)is given by \\(\\mathrm{Pr}(xyz) = |\\langle xyz | \\psi \\rangle |^{2}\\)and as such for the GHZ state probability of obtaining 000 or 111 are both 1/2. To simulate a circuit that includes measurement, we need to add measurements to the original circuit above, and use a different Aer backend. # Create a Classical Register with 3 bits. c = ClassicalRegister( 3 , 'c' ) # Create a Quantum Circuit meas = QuantumCircuit(q, c) meas . barrier(q) # map the quantum measurement to the classical bits meas . measure(q,c) # The Qiskit circuit object supports composition using # the addition operator. qc = circ + meas #drawing the circuit qc . draw() This circuit adds a classical register, and three measurements that are used to map the outcome of qubits to the classical bits. To simulate this circuit, we use the qasm_simulator in Qiskit Aer. Each run of this circuit will yield either the bitstring 000 or 111. To build up statistics about the distribution of the bitstrings (to, e.g., estimate\\(\\mathrm{Pr}(000)$), we need to repeat the circuit many times. The number of times the circuit is repeated can be specified in the execute function, via the shots keyword. # Use Aer's qasm_simulator backend_sim = BasicAer . get_backend( 'qasm_simulator' ) # Execute the circuit on the qasm simulator. # We've set the number of repeats of the circuit # to be 1024, which is the default. job_sim = execute(qc, backend_sim, shots = 1024 ) # Grab the results from the job. result_sim = job_sim . result() Once you have a result object, you can access the counts via the function get_counts(circuit) . This gives you the aggregated binary outcomes of the circuit you submitted. counts = result_sim . get_counts(qc) print (counts) {'000': 506, '111': 518} Approximately 50 percent of the time, the output bitstring is 000. Qiskit also provides a function plot_histogram , which allows you to view the outcomes. from qiskit.visualization import plot_histogram plot_histogram(counts) The estimated outcome probabilities\\(\\mathrm{Pr}(000)\\)and \\(\\mathrm{Pr}(111)\\)are computed by taking the aggregate counts and dividing by the number of shots (times the circuit was repeated). Try changing the shots keyword in the execute function and see how the estimated probabilities change. Running circuits using the IBM Q provider To faciliate access to real quantum computing hardware, we have provided a simple API interface. To access IBM Q devices, you'll need an API token. For the public IBM Q devices, you can generate an API token here (create an account if you don't already have one). For Q Network devices, login to the q-console, click your hub, group, and project, and expand \"Get Access\" to generate your API token and access url. Our IBM Q provider lets you run your circuit on real devices or on our HPC simulator. Currently, this provider exists within Qiskit, and can be imported as shown below. For details on the provider, see The IBM Q Provider . from qiskit import IBMQ After generating your API token, call: IBMQ.save_account('MY_TOKEN') . For Q Network users, you'll also need to include your access url: IBMQ.save_account('MY_TOKEN', 'URL') This will store your IBM Q credentials in a local file. Unless your registration information has changed, you only need to do this once. You may now load your accounts by calling, IBMQ . load_accounts(hub = None ) Once your account has been loaded, you can view the list of backends available to you. print ( \"Available backends:\" ) IBMQ . backends() Available backends: [<IBMQBackend('ibmqx4') from IBMQ()>, <IBMQBackend('ibmqx2') from IBMQ()>, <IBMQBackend('ibmq_16_melbourne') from IBMQ()>, <IBMQSimulator('ibmq_qasm_simulator') from IBMQ()>] Running circuits on real devices Today's quantum information processors are small and noisy, but are advancing at a fast pace. They provide a great opportunity to explore what noisy, intermediate-scale quantum (NISQ) computers can do. The IBM Q provider uses a queue to allocate the devices to users. We now choose a device with the least busy queue that can support our program (has at least 3 qubits). from qiskit.providers.ibmq import least_busy large_enough_devices = IBMQ . backends(filters = lambda x: \\ x . configuration() . n_qubits < 10 and not x . configuration() . simulator) backend = least_busy(large_enough_devices) print ( \"The best backend is \" + backend . name()) The best backend is ibmqx4 To run the circuit on the backend, we need to specify the number of shots and the number of credits we are willing to spend to run the circuit. Then, we execute the circuit on the backend using the execute function. from qiskit.tools.monitor import job_monitor # Number of shots to run the program (experiment); maximum is 8192 shots. # Maximum number of credits to spend on executions. shots = 1024 max_credits = 3 job_exp = execute(qc, backend = backend, \\ shots = shots, max_credits = max_credits) job_monitor(job_exp) Job Status: job has successfully run job_exp has a .result() method that lets us get the results from running our circuit. Note: When the .result() method is called, the code block will wait until the job has finished before releasing the cell. result_exp = job_exp . result() Like before, the counts from the execution can be obtained using get_counts(qc) counts_exp = result_exp . get_counts(qc) plot_histogram([counts_exp,counts]) Simulating circuits using a HPC simulator The IBM Q provider also comes with a remote optimized simulator called ibmq_qasm_simulator . This remote simulator is capable of simulating up to 32 qubits. It can be used the same way as the remote real backends. simulator_backend = IBMQ . get_backend( 'ibmq_qasm_simulator' , hub = None ) # Number of shots to run the program (experiment); maximum is 8192 shots. # Maximum number of credits to spend on executions. shots = 1024 max_credits = 3 job_hpc = execute(qc, backend = simulator_backend,\\ shots = shots, max_credits = max_credits) result_hpc = job_hpc . result() counts_hpc = result_hpc . get_counts(qc) plot_histogram(counts_hpc) Retrieving a previously run job If your experiment takes longer to run then you have time to wait around, or if you simply want to retrieve old jobs, the IBM Q backends allow you to do that. First you would need to note your job's ID: jobID = job_exp . job_id() print ( 'JOB ID: {}' . format(jobID)) JOB ID: 5ccf7d36557a5600718c5793 Given a job ID, that job object can be later reconstructed from the backend using retrieve_job: job_get = backend . retrieve_job(jobID) and then the results can be obtained from the new job object. job_get . result() . get_counts(qc) {'000': 445, '001': 13, '010': 23, '111': 340, '110': 70, '100': 31, '101': 71, '011': 31}","title":"Getting Started with Qiskit"},{"location":"intro/qiskit/#getting-started-with-qiskit","text":"Here, we provide an overview of working with Qiskit. Qiskit provides the basic building blocks necessary to program quantum computers. The fundamental unit of Qiskit is the quantum circuit . A workflow using Qiskit consists of two stages: Build and Execute . Build allows you to make different quantum circuits that represent the problem you are solving, and Execute allows you to run them on different backends. After the jobs have been run, the data is collected. There are methods for putting this data together, depending on the program. This either gives you the answer you wanted, or allows you to make a better program for the next instance. import numpy as np from qiskit import * % matplotlib inline","title":"Getting Started with Qiskit"},{"location":"intro/qiskit/#circuit-basics","text":"","title":"Circuit Basics "},{"location":"intro/qiskit/#building-the-circuit","text":"The basic elements needed for your first program are the QuantumCircuit, and QuantumRegister. # Create a Quantum Register with 3 qubits. q = QuantumRegister( 3 , 'q' ) # Create a Quantum Circuit acting on the q register circ = QuantumCircuit(q) Note: Naming the QuantumRegister is optional and not required. After you create the circuit with its registers, you can add gates (\"operations\") to manipulate the registers. As you proceed through the tutorials you will find more gates and circuits; below is an example of a quantum circuit that makes a three-qubit GHZ state $$|\\psi\\rangle = \\left(|000\\rangle+|111\\rangle\\right)/\\sqrt{2}.$$ To create such a state, we start with a three-qubit quantum register. By default, each qubit in the register is initialized to\\(|0\\rangle\\)To make the GHZ state, we apply the following gates: * A Hadamard gate\\(H\\)on qubit 0, which puts it into a superposition state. * A controlled-Not operation ($C_{X}$) between qubit 0 and qubit 1. * A controlled-Not operation between qubit 0 and qubit 2. On an ideal quantum computer, the state produced by running this circuit would be the GHZ state above. In Qiskit, operations can be added to the circuit one by one, as shown below. # Add a H gate on qubit 0, putting this qubit in superposition. circ . h(q[ 0 ]) # Add a CX (CNOT) gate on control qubit 0 and target qubit 1, putting # the qubits in a Bell state. circ . cx(q[ 0 ], q[ 1 ]) # Add a CX (CNOT) gate on control qubit 0 and target qubit 2, putting # the qubits in a GHZ state. circ . cx(q[ 0 ], q[ 2 ]) <qiskit.extensions.standard.cx.CnotGate at 0x122bbc1d0>","title":"Building the circuit"},{"location":"intro/qiskit/#visualize-circuit","text":"You can visualize your circuit using Qiskit QuantumCircuit.draw() , which plots the circuit in the form found in many textbooks. circ . draw() In this circuit, the qubits are put in order, with qubit zero at the top and qubit two at the bottom. The circuit is read left to right (meaning that gates that are applied earlier in the circuit show up further to the left).","title":"Visualize Circuit"},{"location":"intro/qiskit/#simulating-circuits-using-qiskit-aer","text":"Qiskit Aer is our package for simulating quantum circuits. It provides many different backends for doing a simulation. Here we use the basic Python version.","title":"Simulating circuits using Qiskit Aer "},{"location":"intro/qiskit/#statevector-backend","text":"The most common backend in Qiskit Aer is the statevector_simulator . This simulator returns the quantum state, which is a complex vector of dimensions\\(2^n\\), where \\(n\\) is the number of qubits (so be careful using this as it will quickly get too large to run on your machine). When representing the state of a multi-qubit system, the tensor order used in Qiskit is different than that used in most physics textbooks. Suppose there are \\( n \\) qubits, and qubit \\(j\\) is labeled as \\(Q_{j}\\) Qiskit uses an ordering in which the \\(n^{\\mathrm{th}} \\) qubit is on the left side of the tensor product, so that the basis vectors are labeled as \\(Q_n\\otimes \\cdots \\otimes Q_1\\otimes Q_0\\). For example, if qubit zero is in state 0, qubit 1 is in state 0, and qubit 2 is in state 1, Qiskit would represent this state as\\(|100\\rangle\\), whereas many physics textbooks would represent it as\\(|001\\rangle\\). This difference in labeling affects the way multi-qubit operations are represented as matrices. For example, Qiskit represents a controlled-X (\\( C_{X}\\) operation with qubit 0 being the control and qubit 1 being the target as $$C_X = \\begin{pmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ \\end{pmatrix}.$$ To run the above circuit using the statevector simulator, first you need to import Aer and then set the backend to statevector_simulator . # Import Aer from qiskit import BasicAer # Run the quantum circuit on a statevector simulator backend backend = BasicAer . get_backend( 'statevector_simulator' ) Now that we have chosen the backend, it's time to compile and run the quantum circuit. In Qiskit we provide the execute function for this. execute returns a job object that encapsulates information about the job submitted to the backend. Tip: You can obtain the above parameters in Jupyter. Simply place the text cursor on a function and press Shift+Tab. # Create a Quantum Program for execution job = execute(circ, backend) When you run a program, a job object is made that has the following two useful methods: job.status() and job.result() , which return the status of the job and a result object, respectively. Note: Jobs run asynchronously, but when the result method is called, it switches to synchronous and waits for it to finish before moving on to another task. result = job . result() The results object contains the data and Qiskit provides the method result.get_statevector(circ) to return the state vector for the quantum circuit. outputstate = result . get_statevector(circ, decimals = 3 ) print (outputstate) [0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j] Qiskit also provides a visualization toolbox to allow you to view these results. Below, we use the visualization function to plot the real and imaginary components of the state density matrix \\rho. from qiskit.visualization import plot_state_city plot_state_city(outputstate)","title":"Statevector backend"},{"location":"intro/qiskit/#unitary-backend","text":"Qiskit Aer also includes a unitary_simulator that works provided all the elements in the circuit are unitary operations . This backend calculates the \\(2^n \\times 2^n\\) matrix representing the gates in the quantum circuit. # Run the quantum circuit on a unitary simulator backend backend = BasicAer . get_backend( 'unitary_simulator' ) job = execute(circ, backend) result = job . result() # Show the results print (result . get_unitary(circ, decimals = 3 )) [[ 0.707+0.j 0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j -0.707+0.j] [ 0. +0.j 0. +0.j 0.707+0.j 0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j -0.707+0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j 0.707+0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0.707+0.j -0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j 0.707+0.j] [ 0.707+0.j -0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j]]","title":"Unitary backend"},{"location":"intro/qiskit/#openqasm-backend","text":"The simulators above are useful because they provide information about the state output by the ideal circuit and the matrix representation of the circuit. However, a real experiment terminates by measuring each qubit (usually in the computational\\(|0\\rangle, |1\\rangle\\)basis). Without measurement, we cannot gain information about the state. Measurements cause the quantum system to collapse into classical bits. For example, suppose we make independent measurements on each qubit of the three-qubit GHZ state $$|\\psi\\rangle = |000\\rangle +|111\\rangle)/\\sqrt{2},$$ and let\\(xyz\\)denote the bitstring that results. Recall that, under the qubit labeling used by Qiskit,\\(x\\)would correspond to the outcome on qubit 2,\\(y\\)to the outcome on qubit 1, and\\(z\\)to the outcome on qubit 0. Note: This representation of the bitstring puts the most significant bit (MSB) on the left, and the least significant bit (LSB) on the right. This is the standard ordering of binary bitstrings. We order the qubits in the same way, which is why Qiskit uses a non-standard tensor product order. Recall the probability of obtaining outcome\\(xyz\\)is given by \\(\\mathrm{Pr}(xyz) = |\\langle xyz | \\psi \\rangle |^{2}\\)and as such for the GHZ state probability of obtaining 000 or 111 are both 1/2. To simulate a circuit that includes measurement, we need to add measurements to the original circuit above, and use a different Aer backend. # Create a Classical Register with 3 bits. c = ClassicalRegister( 3 , 'c' ) # Create a Quantum Circuit meas = QuantumCircuit(q, c) meas . barrier(q) # map the quantum measurement to the classical bits meas . measure(q,c) # The Qiskit circuit object supports composition using # the addition operator. qc = circ + meas #drawing the circuit qc . draw() This circuit adds a classical register, and three measurements that are used to map the outcome of qubits to the classical bits. To simulate this circuit, we use the qasm_simulator in Qiskit Aer. Each run of this circuit will yield either the bitstring 000 or 111. To build up statistics about the distribution of the bitstrings (to, e.g., estimate\\(\\mathrm{Pr}(000)$), we need to repeat the circuit many times. The number of times the circuit is repeated can be specified in the execute function, via the shots keyword. # Use Aer's qasm_simulator backend_sim = BasicAer . get_backend( 'qasm_simulator' ) # Execute the circuit on the qasm simulator. # We've set the number of repeats of the circuit # to be 1024, which is the default. job_sim = execute(qc, backend_sim, shots = 1024 ) # Grab the results from the job. result_sim = job_sim . result() Once you have a result object, you can access the counts via the function get_counts(circuit) . This gives you the aggregated binary outcomes of the circuit you submitted. counts = result_sim . get_counts(qc) print (counts) {'000': 506, '111': 518} Approximately 50 percent of the time, the output bitstring is 000. Qiskit also provides a function plot_histogram , which allows you to view the outcomes. from qiskit.visualization import plot_histogram plot_histogram(counts) The estimated outcome probabilities\\(\\mathrm{Pr}(000)\\)and \\(\\mathrm{Pr}(111)\\)are computed by taking the aggregate counts and dividing by the number of shots (times the circuit was repeated). Try changing the shots keyword in the execute function and see how the estimated probabilities change.","title":"OpenQASM backend"},{"location":"intro/qiskit/#running-circuits-using-the-ibm-q-provider","text":"To faciliate access to real quantum computing hardware, we have provided a simple API interface. To access IBM Q devices, you'll need an API token. For the public IBM Q devices, you can generate an API token here (create an account if you don't already have one). For Q Network devices, login to the q-console, click your hub, group, and project, and expand \"Get Access\" to generate your API token and access url. Our IBM Q provider lets you run your circuit on real devices or on our HPC simulator. Currently, this provider exists within Qiskit, and can be imported as shown below. For details on the provider, see The IBM Q Provider . from qiskit import IBMQ After generating your API token, call: IBMQ.save_account('MY_TOKEN') . For Q Network users, you'll also need to include your access url: IBMQ.save_account('MY_TOKEN', 'URL') This will store your IBM Q credentials in a local file. Unless your registration information has changed, you only need to do this once. You may now load your accounts by calling, IBMQ . load_accounts(hub = None ) Once your account has been loaded, you can view the list of backends available to you. print ( \"Available backends:\" ) IBMQ . backends() Available backends: [<IBMQBackend('ibmqx4') from IBMQ()>, <IBMQBackend('ibmqx2') from IBMQ()>, <IBMQBackend('ibmq_16_melbourne') from IBMQ()>, <IBMQSimulator('ibmq_qasm_simulator') from IBMQ()>]","title":"Running circuits using the IBM Q provider "},{"location":"intro/qiskit/#running-circuits-on-real-devices","text":"Today's quantum information processors are small and noisy, but are advancing at a fast pace. They provide a great opportunity to explore what noisy, intermediate-scale quantum (NISQ) computers can do. The IBM Q provider uses a queue to allocate the devices to users. We now choose a device with the least busy queue that can support our program (has at least 3 qubits). from qiskit.providers.ibmq import least_busy large_enough_devices = IBMQ . backends(filters = lambda x: \\ x . configuration() . n_qubits < 10 and not x . configuration() . simulator) backend = least_busy(large_enough_devices) print ( \"The best backend is \" + backend . name()) The best backend is ibmqx4 To run the circuit on the backend, we need to specify the number of shots and the number of credits we are willing to spend to run the circuit. Then, we execute the circuit on the backend using the execute function. from qiskit.tools.monitor import job_monitor # Number of shots to run the program (experiment); maximum is 8192 shots. # Maximum number of credits to spend on executions. shots = 1024 max_credits = 3 job_exp = execute(qc, backend = backend, \\ shots = shots, max_credits = max_credits) job_monitor(job_exp) Job Status: job has successfully run job_exp has a .result() method that lets us get the results from running our circuit. Note: When the .result() method is called, the code block will wait until the job has finished before releasing the cell. result_exp = job_exp . result() Like before, the counts from the execution can be obtained using get_counts(qc) counts_exp = result_exp . get_counts(qc) plot_histogram([counts_exp,counts])","title":"Running circuits on real devices"},{"location":"intro/qiskit/#simulating-circuits-using-a-hpc-simulator","text":"The IBM Q provider also comes with a remote optimized simulator called ibmq_qasm_simulator . This remote simulator is capable of simulating up to 32 qubits. It can be used the same way as the remote real backends. simulator_backend = IBMQ . get_backend( 'ibmq_qasm_simulator' , hub = None ) # Number of shots to run the program (experiment); maximum is 8192 shots. # Maximum number of credits to spend on executions. shots = 1024 max_credits = 3 job_hpc = execute(qc, backend = simulator_backend,\\ shots = shots, max_credits = max_credits) result_hpc = job_hpc . result() counts_hpc = result_hpc . get_counts(qc) plot_histogram(counts_hpc)","title":"Simulating circuits using a HPC simulator"},{"location":"intro/qiskit/#retrieving-a-previously-run-job","text":"If your experiment takes longer to run then you have time to wait around, or if you simply want to retrieve old jobs, the IBM Q backends allow you to do that. First you would need to note your job's ID: jobID = job_exp . job_id() print ( 'JOB ID: {}' . format(jobID)) JOB ID: 5ccf7d36557a5600718c5793 Given a job ID, that job object can be later reconstructed from the backend using retrieve_job: job_get = backend . retrieve_job(jobID) and then the results can be obtained from the new job object. job_get . result() . get_counts(qc) {'000': 445, '001': 13, '010': 23, '111': 340, '110': 70, '100': 31, '101': 71, '011': 31}","title":"Retrieving a previously run job"},{"location":"intro/introduction/intro/","text":"","title":"Intro"},{"location":"intro/mongodb/mongodb/","text":"","title":"Mongodb"},{"location":"intro/parsing/parsing/","text":"","title":"Parsing"},{"location":"introduction/intro/","text":"","title":"Intro"},{"location":"mapping/mapping/","text":"","title":"Mapping Tables"},{"location":"models/clustering/","text":"Coming Soon Under construction","title":"Clustering"},{"location":"models/clustering/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"models/link/","text":"Coming Soon Under construction","title":"Link Prediction"},{"location":"models/link/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"models/random-walk/","text":"Coming Soon Under construction","title":"Randomwalk"},{"location":"models/random-walk/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"mongodb/mongodb/","text":"","title":"Mongodb"},{"location":"node/node/","text":"","title":"Node Implementation"},{"location":"nosql/nosql/","text":"","title":"NoSQL database"},{"location":"parsing/parsing/","text":"","title":"Parsing Pipeline"}]}