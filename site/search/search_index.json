{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ICD 11 Code Tools This online documents has been prepared for ICD 11 Code Tools development and implementation. The document begins with the setting up of tools and environment required for platform creation. A systematic steps for Indexing, Graph database and NoSQL database integration and development is presented. Implementation of AI search algorithms and development of models are introduced. Figure : Counting number of decendent nodes in each categories of ICD 11 code trees.","title":"Home"},{"location":"#icd-11-code-tools","text":"This online documents has been prepared for ICD 11 Code Tools development and implementation. The document begins with the setting up of tools and environment required for platform creation. A systematic steps for Indexing, Graph database and NoSQL database integration and development is presented. Implementation of AI search algorithms and development of models are introduced. Figure : Counting number of decendent nodes in each categories of ICD 11 code trees.","title":"ICD 11 Code Tools"},{"location":"workflow/","text":"Cloud Articture and Workflow This online documents has been prepared for ICD 11 Code Tools development and implementation. The document begins with the setting up of tools and environment required for platform creation. A systematic steps for Indexing, Graph database and NoSQL database integration and development is presented. Implementation of AI search algorithms and development of models are introduced. Figure : Platform architecture and workflow","title":"Workflow"},{"location":"workflow/#cloud-articture-and-workflow","text":"This online documents has been prepared for ICD 11 Code Tools development and implementation. The document begins with the setting up of tools and environment required for platform creation. A systematic steps for Indexing, Graph database and NoSQL database integration and development is presented. Implementation of AI search algorithms and development of models are introduced. Figure : Platform architecture and workflow","title":"Cloud Articture and Workflow"},{"location":"algorithms/alg-I/","text":"","title":"Algorithms - I"},{"location":"algorithms/alg-II/","text":"","title":"Algorithms - II"},{"location":"algorithms/alg-III/","text":"","title":"Algorithms - II"},{"location":"download/download/","text":"ICD 11 Download Pipeline Setting up API To download ICD11 data you need to use the API provided at: https://icd.who.int/icdapi . In order to gain access to the API you need to create an account and use the client key provided. With the client key you are now able to access all of the endpoints specified in the API documentation . The rest of this guide uses the ICD11 module from the ping lab utils package. You can find and clone the module here: https://github.com/salviStudent/testing/tree/master/testing-master . Working Directory and Additonal Dependencies For the simplest use you need to have a json file named config.json in your working directory. The config file needs to have the following: { \"ClientId\":\"your_client_id\", \"ClientSecret\": \"your_client_secret\" } where your_client_id and your_client_secret are your client and secret keys respectively. Along with this config file ICD11.py only needs the request module to function. You can install it by running pip3 install requests if it is not already installed. Getting started Once all of this is in place you are ready to start downloading ICD-11 data. As an example we show the results from the ICD-11 code corresponding to hypertensive heart disease. from ICD11 import icd11_data hypertensive_heart_disease = icd11_data( \"1210166201\" ) print (hypetensive_heart_disease) This outputs: { '@context' : 'http://id.who.int/icd/contexts/contextForFoundationEntity.json' , '@id' : 'http://id.who.int/icd/entity/1210166201' , 'parent' : [ 'http://id.who.int/icd/entity/924915526' , 'http://id.who.int/icd/entity/1395497138' ], 'child' : [ 'http://id.who.int/icd/entity/600660459' , 'http://id.who.int/icd/entity/1208029865' ], 'browserUrl' : 'NA' , 'title' : { '@language' : 'en' , '@value' : 'Hypertensive heart disease' }, 'synonym' : [ { 'label' : { '@language' : 'en' , '@value' : 'HHD - [hypertensive heart disease]' } }, { 'label' : { '@language' : 'en' , '@value' : 'hypertensive cardiac disease' } } ], 'definition' : { '@language' : 'en' , '@value' : 'Uncontrolled and prolonged hypertension can lead to a variety of changes in the myocardial structure, coronary vasculature, and conduction system of the heart. Hypertensive heart disease is a term applied generally to heart diseases, such as left ventricular hypertrophy, coronary artery disease, cardiac arrhythmias, and congestive heart failure, that are caused by direct or indirect effects hypertension.' } }","title":"Download Pipeline"},{"location":"download/download/#icd-11-download-pipeline","text":"","title":"ICD 11 Download Pipeline"},{"location":"download/download/#setting-up-api","text":"To download ICD11 data you need to use the API provided at: https://icd.who.int/icdapi . In order to gain access to the API you need to create an account and use the client key provided. With the client key you are now able to access all of the endpoints specified in the API documentation . The rest of this guide uses the ICD11 module from the ping lab utils package. You can find and clone the module here: https://github.com/salviStudent/testing/tree/master/testing-master .","title":"Setting up API"},{"location":"download/download/#working-directory-and-additonal-dependencies","text":"For the simplest use you need to have a json file named config.json in your working directory. The config file needs to have the following: { \"ClientId\":\"your_client_id\", \"ClientSecret\": \"your_client_secret\" } where your_client_id and your_client_secret are your client and secret keys respectively. Along with this config file ICD11.py only needs the request module to function. You can install it by running pip3 install requests if it is not already installed.","title":"Working Directory and Additonal Dependencies"},{"location":"download/download/#getting-started","text":"Once all of this is in place you are ready to start downloading ICD-11 data. As an example we show the results from the ICD-11 code corresponding to hypertensive heart disease. from ICD11 import icd11_data hypertensive_heart_disease = icd11_data( \"1210166201\" ) print (hypetensive_heart_disease) This outputs: { '@context' : 'http://id.who.int/icd/contexts/contextForFoundationEntity.json' , '@id' : 'http://id.who.int/icd/entity/1210166201' , 'parent' : [ 'http://id.who.int/icd/entity/924915526' , 'http://id.who.int/icd/entity/1395497138' ], 'child' : [ 'http://id.who.int/icd/entity/600660459' , 'http://id.who.int/icd/entity/1208029865' ], 'browserUrl' : 'NA' , 'title' : { '@language' : 'en' , '@value' : 'Hypertensive heart disease' }, 'synonym' : [ { 'label' : { '@language' : 'en' , '@value' : 'HHD - [hypertensive heart disease]' } }, { 'label' : { '@language' : 'en' , '@value' : 'hypertensive cardiac disease' } } ], 'definition' : { '@language' : 'en' , '@value' : 'Uncontrolled and prolonged hypertension can lead to a variety of changes in the myocardial structure, coronary vasculature, and conduction system of the heart. Hypertensive heart disease is a term applied generally to heart diseases, such as left ventricular hypertrophy, coronary artery disease, cardiac arrhythmias, and congestive heart failure, that are caused by direct or indirect effects hypertension.' } }","title":"Getting started"},{"location":"explore/explore/","text":"","title":"Exploratory Data Analysis"},{"location":"flask/flask/","text":"","title":"Flask Implementation"},{"location":"graph/graph/","text":"","title":"Graphical Database"},{"location":"indexing/indexing/","text":"","title":"Indexing"},{"location":"mapping/mapping/","text":"","title":"Mapping Tables"},{"location":"models/clustering/","text":"Coming Soon Under construction","title":"Clustering"},{"location":"models/clustering/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"models/link/","text":"Coming Soon Under construction","title":"Link Prediction"},{"location":"models/link/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"models/random-walk/","text":"Coming Soon Under construction","title":"Randomwalk"},{"location":"models/random-walk/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"node/node/","text":"","title":"Node Implementation"},{"location":"nosql/nosql/","text":"","title":"NoSQL database"},{"location":"parsing/parsing/","text":"","title":"Parsing Pipeline"},{"location":"setup/anaconda/","text":"Installing Python To install Anaconda Python follow the instruction at Anaconda Distribution Website . Based on the operating system select the proper version of the Anaconda package and install it in your PC. After you successfully install the proper version, you will get anaconda application in you PC which will look like the figure below: Best way to start with is the \"Jupyter notebook\". Lunch the jupyter notebook to start with Python. Note- Linux: For Linux user, it could be little bit tricky. SOme time it becomes hard to locate anaconda path to the environment so you need to point the python you want to use. Please, run the command below to point the python: bash export PATH=/home/ubuntu/anaconda3/bin:$PATH There is 'base' or 'anaconda3' environment by defult. You can find the list of available environmet by typing following command on the terminal bash conda env list To start the 'base' environment type bash source activate base To install new package for example 'jupyter notebook' type bash pip install jupyter notebook After sucessfully installing Jupyter notebook, tye following to start it bash Jupyter notebook Note - Cloud For running Jupyter notebook in AWS cloud, it is important to open the \"8888\" to \"8889\" with TCP rule with IP \"0.0.0.0\" and allow to be opend from anywhere. Once port is open, type following to bash jupyter notebook --ip=0.0.0.0 --no-browser","title":"Setting up Python"},{"location":"setup/anaconda/#installing-python","text":"To install Anaconda Python follow the instruction at Anaconda Distribution Website . Based on the operating system select the proper version of the Anaconda package and install it in your PC. After you successfully install the proper version, you will get anaconda application in you PC which will look like the figure below: Best way to start with is the \"Jupyter notebook\". Lunch the jupyter notebook to start with Python.","title":"Installing Python"},{"location":"setup/anaconda/#note-linux","text":"For Linux user, it could be little bit tricky. SOme time it becomes hard to locate anaconda path to the environment so you need to point the python you want to use. Please, run the command below to point the python: bash export PATH=/home/ubuntu/anaconda3/bin:$PATH There is 'base' or 'anaconda3' environment by defult. You can find the list of available environmet by typing following command on the terminal bash conda env list To start the 'base' environment type bash source activate base To install new package for example 'jupyter notebook' type bash pip install jupyter notebook After sucessfully installing Jupyter notebook, tye following to start it bash Jupyter notebook","title":"Note- Linux:"},{"location":"setup/anaconda/#note-cloud","text":"For running Jupyter notebook in AWS cloud, it is important to open the \"8888\" to \"8889\" with TCP rule with IP \"0.0.0.0\" and allow to be opend from anywhere. Once port is open, type following to bash jupyter notebook --ip=0.0.0.0 --no-browser","title":"Note - Cloud"},{"location":"setup/env/","text":"Python Environment Basics To avoid errors later, it's best to update all the packages in the default environment. Open the Anaconda Prompt application. In the prompt, run the following commands: conda upgrade conda conda upgrade --all If you are seeing the following \"conda command not found\" and are using ZShell, you have to do the following: export PATH = \"/Users/username/anaconda/bin: $PATH \" or update above command line to your .zsh_config file. Once you have Anaconda installed, managing packages is fairly straightforward. To install a package, type conda install package_name in your terminal. For example, to install numpy, type conda install numpy. You can install multiple packages at the same time. Something like conda install numpy scipy pandas will install all those packages simultaneously. It's also possible to specify which version of a package you want by adding the version number such as conda install numpy = 1 .10. Conda also automatically installs dependencies for you. For example scipy depends on numpy, it uses and requires numpy. If you install just scipy (conda install scipy), Conda will also install numpy if it isn't already installed. Most of the commands are pretty intuitive. To uninstall, use conda remove package_name To update a package conda update package_name If you want to update all packages in an environment, which is often useful, use conda update --all And finally, to list installed packages, it's conda list If you don't know the exact name of the package you're looking for, you can try searching with conda search search_term For example, I know I want to install Beautiful Soup, but I'm not sure of the exact package name. So, I try conda search beautifulsoup Environments Conda can be used to create environments to isolate your projects. To create an environment, use conda create -n env_name list of packages in your terminal Here -n env_name sets the name of your environment (-n for name) and list of packages is the list of packages you want installed in the environment. For example, to create an environment named my_env and install numpy in it, type conda create -n my_env numpy When creating an environment, you can specify which version of Python to install in the environment. This is useful when you're working with code in both Python 2.x and Python 3.x. To create an environment with a specific Python version, do something like conda create -n py3 python = 3 or conda create -n py2 python = 2 I actually have both of these environments on my personal computer. I use them as general environments not tied to any specific project, but rather for general work with each Python version easily accessible. These commands will install the most recent version of Python 3 and 2, respectively. To install a specific version, use conda create -n py python = 3 .3 for Python 3.3. Once you have an environment created, use source activate my_env to enter it on OSX/Linux. On Windows, use activate my_env When you're in the environment, you'll see the environment name in the terminal prompt. Something like (my_env) ~ $. The environment has only a few packages installed by default, plus the ones you installed when creating it. You can check this out with conda list. Installing packages in the environment is the same as before: conda install package_name Only this time, the specific packages you install will only be available when you're in the environment. To leave the environment, type source deactivate ( on OSX/Linux ) On Windows, use deactivate Saving and loading environments A really useful feature is sharing environments so others can install all the packages used in your code, with the correct versions. You can save the packages to a YAML file with conda env export > environment.yaml The first part conda env export writes out all the packages in the environment, including the Python version. Above you can see the name of the environment and all the dependencies (along with versions) are listed. The second part of the export command, > environment.yaml writes the exported text to a YAML file environment.yaml . This file can now be shared and others will be able to create the same environment you used for the project. To create an environment from an environment file use conda env create -f environment.yaml This will create a new environment with the same name listed in environment.yaml . Listing environments If you forget what your environments are named (happens to me sometimes), use conda env list to list out all the environments you've created. You should see a list of environments, there will be an asterisk next to the environment you're currently in. The default environment, the environment used when you aren't in one, is called root . Removing environments If there are environments you don't use anymore, conda env remove -n env_name will remove the specified environment (here, named env_name ). Using environments One thing that\u2019s helped me tremendously is having separate environments for Python 2 and Python 3. I used conda create -n py2 python = 2 and conda create -n py3 python = 3 to create two separate environments, py2 and py3 . Now I have a general use environment for each Python version. In each of those environments, I've installed most of the standard data science packages (numpy, scipy, pandas, etc.) I\u2019ve also found it useful to create environments for each project I\u2019m working on. It works great for non-data related projects too like web apps with Flask. For example, I have an environment for my personal blog using Pelican . Sharing environments When sharing your code on GitHub, it's good practice to make an environment file and include it in the repository. This will make it easier for people to install all the dependencies for your code. I also usually include a pip requirements.txt file using pip freeze ( learn more here ) for people not using conda. More to learn To learn more about conda and how it fits in the Python ecosystem, check out this article by Jake Vanderplas: Conda myths and misconceptions. And here's the conda documentation you can reference later.","title":"Setting up Node"},{"location":"setup/env/#python-environment","text":"","title":"Python Environment"},{"location":"setup/env/#basics","text":"To avoid errors later, it's best to update all the packages in the default environment. Open the Anaconda Prompt application. In the prompt, run the following commands: conda upgrade conda conda upgrade --all If you are seeing the following \"conda command not found\" and are using ZShell, you have to do the following: export PATH = \"/Users/username/anaconda/bin: $PATH \" or update above command line to your .zsh_config file. Once you have Anaconda installed, managing packages is fairly straightforward. To install a package, type conda install package_name in your terminal. For example, to install numpy, type conda install numpy. You can install multiple packages at the same time. Something like conda install numpy scipy pandas will install all those packages simultaneously. It's also possible to specify which version of a package you want by adding the version number such as conda install numpy = 1 .10. Conda also automatically installs dependencies for you. For example scipy depends on numpy, it uses and requires numpy. If you install just scipy (conda install scipy), Conda will also install numpy if it isn't already installed. Most of the commands are pretty intuitive. To uninstall, use conda remove package_name To update a package conda update package_name If you want to update all packages in an environment, which is often useful, use conda update --all And finally, to list installed packages, it's conda list If you don't know the exact name of the package you're looking for, you can try searching with conda search search_term For example, I know I want to install Beautiful Soup, but I'm not sure of the exact package name. So, I try conda search beautifulsoup","title":"Basics"},{"location":"setup/env/#environments","text":"Conda can be used to create environments to isolate your projects. To create an environment, use conda create -n env_name list of packages in your terminal Here -n env_name sets the name of your environment (-n for name) and list of packages is the list of packages you want installed in the environment. For example, to create an environment named my_env and install numpy in it, type conda create -n my_env numpy When creating an environment, you can specify which version of Python to install in the environment. This is useful when you're working with code in both Python 2.x and Python 3.x. To create an environment with a specific Python version, do something like conda create -n py3 python = 3 or conda create -n py2 python = 2 I actually have both of these environments on my personal computer. I use them as general environments not tied to any specific project, but rather for general work with each Python version easily accessible. These commands will install the most recent version of Python 3 and 2, respectively. To install a specific version, use conda create -n py python = 3 .3 for Python 3.3. Once you have an environment created, use source activate my_env to enter it on OSX/Linux. On Windows, use activate my_env When you're in the environment, you'll see the environment name in the terminal prompt. Something like (my_env) ~ $. The environment has only a few packages installed by default, plus the ones you installed when creating it. You can check this out with conda list. Installing packages in the environment is the same as before: conda install package_name Only this time, the specific packages you install will only be available when you're in the environment. To leave the environment, type source deactivate ( on OSX/Linux ) On Windows, use deactivate","title":"Environments"},{"location":"setup/env/#saving-and-loading-environments","text":"A really useful feature is sharing environments so others can install all the packages used in your code, with the correct versions. You can save the packages to a YAML file with conda env export > environment.yaml The first part conda env export writes out all the packages in the environment, including the Python version. Above you can see the name of the environment and all the dependencies (along with versions) are listed. The second part of the export command, > environment.yaml writes the exported text to a YAML file environment.yaml . This file can now be shared and others will be able to create the same environment you used for the project. To create an environment from an environment file use conda env create -f environment.yaml This will create a new environment with the same name listed in environment.yaml .","title":"Saving and loading environments"},{"location":"setup/env/#listing-environments","text":"If you forget what your environments are named (happens to me sometimes), use conda env list to list out all the environments you've created. You should see a list of environments, there will be an asterisk next to the environment you're currently in. The default environment, the environment used when you aren't in one, is called root .","title":"Listing environments"},{"location":"setup/env/#removing-environments","text":"If there are environments you don't use anymore, conda env remove -n env_name will remove the specified environment (here, named env_name ).","title":"Removing environments"},{"location":"setup/env/#using-environments","text":"One thing that\u2019s helped me tremendously is having separate environments for Python 2 and Python 3. I used conda create -n py2 python = 2 and conda create -n py3 python = 3 to create two separate environments, py2 and py3 . Now I have a general use environment for each Python version. In each of those environments, I've installed most of the standard data science packages (numpy, scipy, pandas, etc.) I\u2019ve also found it useful to create environments for each project I\u2019m working on. It works great for non-data related projects too like web apps with Flask. For example, I have an environment for my personal blog using Pelican .","title":"Using environments"},{"location":"setup/env/#sharing-environments","text":"When sharing your code on GitHub, it's good practice to make an environment file and include it in the repository. This will make it easier for people to install all the dependencies for your code. I also usually include a pip requirements.txt file using pip freeze ( learn more here ) for people not using conda.","title":"Sharing environments"},{"location":"setup/env/#more-to-learn","text":"To learn more about conda and how it fits in the Python ecosystem, check out this article by Jake Vanderplas: Conda myths and misconceptions. And here's the conda documentation you can reference later.","title":"More to learn"},{"location":"setup/git/","text":"How to git Reference : How to Git Create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files. You can add these files after your project has been pushed to GitHub. Open Terminal. Change the current working directory to your local project. Initialize the local directory as a Git repository. git init Add the files in your new local repository. This stages them for the first commit. git add . Adds the files in the local repository and stages them for commit. To unstage a file, use 'git reset HEAD YOUR-FILE'. Commit the files that you've staged in your local repository. git commit -m \"First commit\" Commits the tracked changes and prepares them to be pushed to a remote repository. To remove this commit and modify the file, use 'git reset --soft HEAD~1' and commit and add the file again. Copy remote repository URL fieldAt the top of your GitHub repository's Quick Setup page, click to copy the remote repository URL. In Terminal, add the URL for the remote repository where your local repository will be pushed. git remote add origin remote repository URL Sets the new remote git remote -v Verifies the new remote URL Push the changes in your local repository to GitHub. git push origin master Pushes the changes in your local repository up to the remote repository you specified as the origin","title":"Setting up Git"},{"location":"setup/git/#how-to-git","text":"Reference : How to Git Create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files. You can add these files after your project has been pushed to GitHub. Open Terminal. Change the current working directory to your local project. Initialize the local directory as a Git repository. git init Add the files in your new local repository. This stages them for the first commit. git add . Adds the files in the local repository and stages them for commit. To unstage a file, use 'git reset HEAD YOUR-FILE'. Commit the files that you've staged in your local repository. git commit -m \"First commit\" Commits the tracked changes and prepares them to be pushed to a remote repository. To remove this commit and modify the file, use 'git reset --soft HEAD~1' and commit and add the file again. Copy remote repository URL fieldAt the top of your GitHub repository's Quick Setup page, click to copy the remote repository URL. In Terminal, add the URL for the remote repository where your local repository will be pushed. git remote add origin remote repository URL Sets the new remote git remote -v Verifies the new remote URL Push the changes in your local repository to GitHub. git push origin master Pushes the changes in your local repository up to the remote repository you specified as the origin","title":"How to git"},{"location":"setup/jupyter/","text":"Installing Jupyter Notebook By far the easiest way to install Jupyter is with Anaconda. Jupyter notebooks automatically come with the distribution. You'll be able to use notebooks from the default environment. To install Jupyter notebooks in a conda environment, use conda install jupyter notebook Jupyter notebooks are also available through pip with pip install jupyter notebook Markdown Cheatsheet : https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet Convert a notebook to an HTML file, in your terminal use jupyter nbconvert --to html notebook.ipynb Convert: https://nbconvert.readthedocs.io/en/latest/usage.html To create the slideshow from the notebook file, you'll need to use nbconvert: jupyter nbconvert notebook.ipynb --to slides This just converts the notebook to the necessary files for the slideshow, but you need to serve it with an HTTP server to actually see the presentation. To convert it and immediately see it, use jupyter nbconvert notebook.ipynb --to slides --post serve This will open up the slideshow in your browser so you can present it. panda presentation: presentation","title":"Setting up Elasticsearch"},{"location":"setup/jupyter/#installing-jupyter-notebook","text":"By far the easiest way to install Jupyter is with Anaconda. Jupyter notebooks automatically come with the distribution. You'll be able to use notebooks from the default environment. To install Jupyter notebooks in a conda environment, use conda install jupyter notebook Jupyter notebooks are also available through pip with pip install jupyter notebook Markdown Cheatsheet : https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet Convert a notebook to an HTML file, in your terminal use jupyter nbconvert --to html notebook.ipynb Convert: https://nbconvert.readthedocs.io/en/latest/usage.html To create the slideshow from the notebook file, you'll need to use nbconvert: jupyter nbconvert notebook.ipynb --to slides This just converts the notebook to the necessary files for the slideshow, but you need to serve it with an HTTP server to actually see the presentation. To convert it and immediately see it, use jupyter nbconvert notebook.ipynb --to slides --post serve This will open up the slideshow in your browser so you can present it. panda presentation: presentation","title":"Installing Jupyter Notebook"},{"location":"setup/lib/","text":"Python Libraries Following are the best Python Libraries: TensorFlow Scikit-Learn Numpy Keras PyTorch LightGBM Eli5 SciPy Theano Pandas","title":"Setting up Neo4J"},{"location":"setup/lib/#python-libraries","text":"Following are the best Python Libraries: TensorFlow Scikit-Learn Numpy Keras PyTorch LightGBM Eli5 SciPy Theano Pandas","title":"Python Libraries"}]}